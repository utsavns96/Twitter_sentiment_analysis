{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obama Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we first specify all the imports that we'll need for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data from the input excel into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1: positive, -1: negative, 0: neutral, 2: mixed</td>\n",
       "      <td>Class</td>\n",
       "      <td>Your class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:28:53-05:00</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-10 00:00:00</td>\n",
       "      <td>10:09:00-05:00</td>\n",
       "      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:04:30-05:00</td>\n",
       "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:00:36-05:00</td>\n",
       "      <td>RT @davewiner Slate: Blame &lt;e&gt;Obama&lt;/e&gt; for fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date            time  \\\n",
       "0         NaN                  NaN             NaN   \n",
       "1         NaN  2012-10-16 00:00:00  10:28:53-05:00   \n",
       "2         NaN  2016-12-10 00:00:00  10:09:00-05:00   \n",
       "3         NaN  2012-10-16 00:00:00  10:04:30-05:00   \n",
       "4         NaN  2012-10-16 00:00:00  10:00:36-05:00   \n",
       "\n",
       "                                     Anootated tweet Unnamed: 4  Unnamed: 5  \n",
       "0    1: positive, -1: negative, 0: neutral, 2: mixed      Class  Your class  \n",
       "1  Kirkpatrick, who wore a baseball cap embroider...          0         NaN  \n",
       "2  Question: If <e>Romney</e> and <e>Obama</e> ha...          2         NaN  \n",
       "3  #<e>obama</e> debates that Cracker Ass Cracker...          1         NaN  \n",
       "4  RT @davewiner Slate: Blame <e>Obama</e> for fo...          2         NaN  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loading\n",
    "data = pd.ExcelFile('C:/Users/utsav/OneDrive/UIC/Fall_2023/CS_583/Project/training-Obama-Romney-tweets.xlsx')\n",
    "obama = pd.read_excel(data, 'Obama')\n",
    "obama.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start cleaning the data.<br>\n",
    "We drop the first row from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:28:53-05:00</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-10 00:00:00</td>\n",
       "      <td>10:09:00-05:00</td>\n",
       "      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:04:30-05:00</td>\n",
       "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:00:36-05:00</td>\n",
       "      <td>RT @davewiner Slate: Blame &lt;e&gt;Obama&lt;/e&gt; for fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:50:08-05:00</td>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date            time  \\\n",
       "1         NaN  2012-10-16 00:00:00  10:28:53-05:00   \n",
       "2         NaN  2016-12-10 00:00:00  10:09:00-05:00   \n",
       "3         NaN  2012-10-16 00:00:00  10:04:30-05:00   \n",
       "4         NaN  2012-10-16 00:00:00  10:00:36-05:00   \n",
       "5         NaN  2012-10-16 00:00:00  09:50:08-05:00   \n",
       "\n",
       "                                     Anootated tweet Unnamed: 4 Unnamed: 5  \n",
       "1  Kirkpatrick, who wore a baseball cap embroider...          0        NaN  \n",
       "2  Question: If <e>Romney</e> and <e>Obama</e> ha...          2        NaN  \n",
       "3  #<e>obama</e> debates that Cracker Ass Cracker...          1        NaN  \n",
       "4  RT @davewiner Slate: Blame <e>Obama</e> for fo...          2        NaN  \n",
       "5  @Hollivan @hereistheanswer  Youre missing the ...          0        NaN  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama = obama[1:]\n",
    "obama.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can drop the columns that we do not need, namely: `Unnamed: 0`, `date`, `time` and `Unnamed: 5`.<br>\n",
    "We also rename `Unnamed: 4 ` to `class` and `Anootated tweet` to `tweet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @davewiner Slate: Blame &lt;e&gt;Obama&lt;/e&gt; for fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet class\n",
       "1  Kirkpatrick, who wore a baseball cap embroider...     0\n",
       "2  Question: If <e>Romney</e> and <e>Obama</e> ha...     2\n",
       "3  #<e>obama</e> debates that Cracker Ass Cracker...     1\n",
       "4  RT @davewiner Slate: Blame <e>Obama</e> for fo...     2\n",
       "5  @Hollivan @hereistheanswer  Youre missing the ...     0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama = obama.drop(['Unnamed: 0', 'date', 'time', 'Unnamed: 5'], axis=1)\n",
    "obama = obama.rename(columns={'Unnamed: 4': 'class', 'Anootated tweet': 'tweet'})\n",
    "obama.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of classes available in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1            1922\n",
      "0             1896\n",
      "1             1653\n",
      "2             1474\n",
      "0               82\n",
      "2               70\n",
      "-1              46\n",
      "1               26\n",
      "irrevelant      23\n",
      "irrelevant       1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(obama['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we are only interested in the classes `-1, 0 and 1`. Therefore, we drop all the other classes from the dataframe.<br>\n",
    "We also change the column to be an integer, since the values are a mix of string and integers right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    1978\n",
      "-1    1968\n",
      " 1    1679\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was raised as a Democrat  left the party yea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The &lt;e&gt;Obama camp&lt;/e&gt; can't afford to lower ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "1  Kirkpatrick, who wore a baseball cap embroider...      0\n",
       "3  #<e>obama</e> debates that Cracker Ass Cracker...      1\n",
       "5  @Hollivan @hereistheanswer  Youre missing the ...      0\n",
       "7  I was raised as a Democrat  left the party yea...     -1\n",
       "8  The <e>Obama camp</e> can't afford to lower ex...      0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_df = obama[obama['class'].isin(['-1', '0', '1',-1,0,1])].copy(deep=True)\n",
    "obama_df['class']=obama_df['class'].astype(int)\n",
    "print(obama_df['class'].value_counts())\n",
    "obama_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start working on the actual tweets. The first few steps that we need to perform are cleaning the text itself and tokenizing it.<br>\n",
    "For that, we use 2 functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utsav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub(r'www.[^ ]+', '', text)\n",
    "    text = re.sub(r'[^a-z]', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "regexp = RegexpTokenizer('\\w+')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def tokenize(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = clean(text)\n",
    "    text = regexp.tokenize(text)\n",
    "    text = [w for w in text if w not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below performs the task of going through our dataset, cleaning and tokenizing every tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_df['tweet_token'] = obama_df['tweet'].apply(lambda stext: tokenize(str(stext)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then remove the words that are less than 2 characters, and appear less than 2 times, since those are most likely noise and would not contribute anything to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove words with length less than 2\n",
    "obama_df['tweet_string'] = obama_df['tweet_token'].apply(lambda x:' '.join([item for item in x if len(item)>2]))\n",
    "#Find a frequency distribution, and remove words with frequency less than 1\n",
    "all_words = ' '.join([text for text in obama_df['tweet_string']])\n",
    "tokenized_obama_df = nltk.tokenize.word_tokenize(all_words)\n",
    "fdist = FreqDist(tokenized_obama_df)\n",
    "obama_df['tweet_string_fdist'] = obama_df['tweet_token'].apply(lambda x: ' '.join([item for item in x if fdist[item] > 1 ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to perform the important task of Lemmatizing our dataset. To do this, we use `WordNetLemmatizer` with `Parts-Of-Speech tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\utsav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatiser(text):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(text))  \n",
    "    wordnet_tagged = map(lambda x: (x[0], pos_tagger(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_string</th>\n",
       "      <th>tweet_string_fdist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wore cap barack obama signature look jason jou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[kirkpatrick, wore, baseball, cap, embroidered...</td>\n",
       "      <td>kirkpatrick wore baseball cap embroidered bara...</td>\n",
       "      <td>wore cap barack obama signature look jason jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obama debate cracker as cracker tonight</td>\n",
       "      <td>1</td>\n",
       "      <td>[e, obama, e, debates, cracker, ass, cracker, ...</td>\n",
       "      <td>obama debates cracker ass cracker tonight tuned</td>\n",
       "      <td>obama debates cracker ass cracker tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miss point afraid understand big picture dont ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[youre, missing, point, im, afraid, understand...</td>\n",
       "      <td>youre missing point afraid understand bigger p...</td>\n",
       "      <td>missing point afraid understand bigger picture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>raise democrat leave party year ago never see ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[raised, democrat, left, party, years, ago, li...</td>\n",
       "      <td>raised democrat left party years ago lifetime ...</td>\n",
       "      <td>raised democrat left party years ago never see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>obama camp afford low expectation tonight deba...</td>\n",
       "      <td>0</td>\n",
       "      <td>[e, obama, camp, e, afford, lower, expectation...</td>\n",
       "      <td>obama camp afford lower expectations tonight d...</td>\n",
       "      <td>obama camp afford lower expectations tonight d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class  \\\n",
       "1  wore cap barack obama signature look jason jou...      0   \n",
       "3            obama debate cracker as cracker tonight      1   \n",
       "5  miss point afraid understand big picture dont ...      0   \n",
       "7  raise democrat leave party year ago never see ...     -1   \n",
       "8  obama camp afford low expectation tonight deba...      0   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "1  [kirkpatrick, wore, baseball, cap, embroidered...   \n",
       "3  [e, obama, e, debates, cracker, ass, cracker, ...   \n",
       "5  [youre, missing, point, im, afraid, understand...   \n",
       "7  [raised, democrat, left, party, years, ago, li...   \n",
       "8  [e, obama, camp, e, afford, lower, expectation...   \n",
       "\n",
       "                                        tweet_string  \\\n",
       "1  kirkpatrick wore baseball cap embroidered bara...   \n",
       "3    obama debates cracker ass cracker tonight tuned   \n",
       "5  youre missing point afraid understand bigger p...   \n",
       "7  raised democrat left party years ago lifetime ...   \n",
       "8  obama camp afford lower expectations tonight d...   \n",
       "\n",
       "                                  tweet_string_fdist  \n",
       "1  wore cap barack obama signature look jason jou...  \n",
       "3          obama debates cracker ass cracker tonight  \n",
       "5  missing point afraid understand bigger picture...  \n",
       "7  raised democrat left party years ago never see...  \n",
       "8  obama camp afford lower expectations tonight d...  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_df['tweet'] = obama_df['tweet_string_fdist'].apply(lambda x: lemmatiser(x))\n",
    "obama_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop the columns `tweet_token`, `tweet_string` and `tweet_string_fdist` now.<br>\n",
    "We also remove the null values, to make sure that we do not have any empty records left after the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5625, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wore cap barack obama signature look jason jou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obama debate cracker as cracker tonight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miss point afraid understand big picture dont ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>raise democrat leave party year ago never see ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>obama camp afford low expectation tonight deba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "1  wore cap barack obama signature look jason jou...      0\n",
       "3            obama debate cracker as cracker tonight      1\n",
       "5  miss point afraid understand big picture dont ...      0\n",
       "7  raise democrat leave party year ago never see ...     -1\n",
       "8  obama camp afford low expectation tonight deba...      0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_df = obama_df.drop(['tweet_token', 'tweet_string', 'tweet_string_fdist'], axis=1)\n",
    "obama_df.dropna(inplace=True)\n",
    "print(obama_df.shape)\n",
    "obama_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a look at the distribution of the classes in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    1978\n",
      "-1    1968\n",
      " 1    1679\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(obama_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and test data splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for processing. To train and test our models, we will perform a train-test-split of 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = obama_df['tweet']\n",
    "df_Y = obama_df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X,df_Y,test_size=0.2,random_state = 1551)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `TfidfVectorizer` from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, ngram_range=(1,2))\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also try using `Word2Vec` from `gensim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "obama_df['clean_text_tok']=[nltk.word_tokenize(i) for i in obama_df['tweet']] \n",
    "model = Word2Vec(obama_df['clean_text_tok'],min_count=1) \n",
    "w2v = dict(zip(model.wv.index_to_key , model.wv.vectors))   \n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_val_vectors_w2v = modelw.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to create and test on our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start running our models, to make things easier, we will create a dataframe to keep a track of our performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(columns=['Model','Vectorization','Accuracy', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things even easier, I have written a small function to store our metrics in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metrics(model_name,vector_name,test,predictions):\n",
    "    global performance\n",
    "    new_data = {'Model': model_name,\n",
    "                'Vectorization': vector_name,\n",
    "                'Accuracy': round(accuracy_score(test,predictions),2),\n",
    "                'Precision': round(precision_score(test,predictions, average='weighted'),2),\n",
    "                'Recall': round(recall_score(test,predictions, average='weighted'),2),\n",
    "                'F1 Score': round(f1_score(test,predictions, average='weighted'),2)}\n",
    "    performance = performance.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.61      0.61       428\n",
      "           0       0.49      0.52      0.51       365\n",
      "           1       0.62      0.57      0.59       332\n",
      "\n",
      "    accuracy                           0.57      1125\n",
      "   macro avg       0.57      0.57      0.57      1125\n",
      "weighted avg       0.57      0.57      0.57      1125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\AppData\\Local\\Temp\\ipykernel_23448\\1469057837.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance = performance.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "lr_model_tfidf = LogisticRegression(solver='saga',C=5,penalty='l2',random_state=44) #4=57%\n",
    "lr_model_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
    "lr_tfidf_y_pred = lr_model_tfidf.predict(X_test_vectors_tfidf)\n",
    "print(classification_report(y_test,lr_tfidf_y_pred))\n",
    "write_metrics('Logistic Regression','TF-IDF',y_test,lr_tfidf_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.56      0.55       428\n",
      "           0       0.42      0.47      0.44       365\n",
      "           1       0.50      0.40      0.45       332\n",
      "\n",
      "    accuracy                           0.48      1125\n",
      "   macro avg       0.49      0.48      0.48      1125\n",
      "weighted avg       0.49      0.48      0.48      1125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\AppData\\Local\\Temp\\ipykernel_23448\\1469057837.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance = performance.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "lr_model_w2v = LogisticRegression(solver='liblinear',C=10,penalty='l2',random_state=4) #4=57%\n",
    "lr_model_w2v.fit(X_train_vectors_w2v, y_train)\n",
    "lr_w2v_y_pred = lr_model_w2v.predict(X_val_vectors_w2v)\n",
    "print(classification_report(y_test,lr_w2v_y_pred))\n",
    "write_metrics('Logistic Regression','Word2Vec',y_test,lr_w2v_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Vectorization  Accuracy  Precision  Recall  F1 Score\n",
       "0  Logistic Regression        TF-IDF      0.57       0.57    0.57      0.57\n",
       "1  Logistic Regression      Word2Vec      0.48       0.49    0.48      0.48"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS418",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
