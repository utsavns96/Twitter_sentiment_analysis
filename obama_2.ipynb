{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obama\n",
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and renaming the dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#data loading\n",
    "data = pd.ExcelFile('C:/Users/utsav/OneDrive/UIC/Fall_2023/CS_583/Project/training-Obama-Romney-tweets.xlsx')\n",
    "obama = pd.read_excel(data, 'Obama')\n",
    "#data cleaning\n",
    "obama = obama[1:]\n",
    "obama = obama.drop(['Unnamed: 0', 'date', 'time', 'Unnamed: 5'], axis=1)\n",
    "obama = obama.rename(columns={'Unnamed: 4': 'class', 'Anootated tweet': 'tweet'})\n",
    "performance = pd.DataFrame(columns=['Model','Accuracy', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1            1922\n",
      "0             1896\n",
      "1             1653\n",
      "2             1474\n",
      "0               82\n",
      "2               70\n",
      "-1              46\n",
      "1               26\n",
      "irrevelant      23\n",
      "irrelevant       1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(obama['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obama = obama[obama['class'].isin(['-1', '0', '1'])]\n",
    "obama = obama.dropna()\n",
    "#obama = obama.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_mixed = obama[obama['class'].isin(['2',2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama = obama[obama['class'].isin(['-1', '0', '1','2',2,-1,0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama['class']=obama['class'].astype(int)\n",
    "obama['class']=obama['class'].apply(lambda x: 0 if x==2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    3520\n",
      "-1    1968\n",
      " 1    1679\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(obama['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama['sentiment'] = obama['class'].apply(lambda x: 'positive' if x == 1 else 'neutral' if x==0 else 'negative')\n",
    "#obama['sentiment'] = obama['class'].map({1: 'positive', 0: 'neutral', -1: 'negative'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utsav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub(r'www.[^ ]+', '', text)\n",
    "    text = re.sub(r'[^a-z]', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "regexp = RegexpTokenizer('\\w+')\n",
    "# import spacy\n",
    "nltk.download('stopwords')\n",
    "def tokenize(text):\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    text = clean(text)\n",
    "    #text = nltk.word_tokenize(text)\n",
    "    text = regexp.tokenize(text)\n",
    "    text = [w for w in text if w not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama['tweet_token'] = obama['tweet'].apply(lambda stext: tokenize(str(stext)))\n",
    "\n",
    "#remove words with length less than 2\n",
    "obama['tweet_string'] = obama['tweet_token'].apply(lambda x:' '.join([item for item in x if len(item)>2]))\n",
    "\n",
    "all_words = ' '.join([text for text in obama['tweet_string']])\n",
    "tokenized_obama = nltk.tokenize.word_tokenize(all_words)\n",
    "fdist = FreqDist(tokenized_obama)\n",
    "obama['tweet_string_fdist'] = obama['tweet_token'].apply(lambda x: ' '.join([item for item in x if fdist[item] > 1 ]))\n",
    "#fdist\n",
    "#lemmatize\n",
    "# nltk.download('wordnet') \n",
    "# wordnet_lem = WordNetLemmatizer()\n",
    "# obama['tweet'] = obama['tweet_string_fdist'].apply(wordnet_lem.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\utsav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatiser(text):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(text))  \n",
    "    wordnet_tagged = map(lambda x: (x[0], pos_tagger(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_string</th>\n",
       "      <th>tweet_string_fdist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wore cap barack obama signature look jason jou...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[kirkpatrick, wore, baseball, cap, embroidered...</td>\n",
       "      <td>kirkpatrick wore baseball cap embroidered bara...</td>\n",
       "      <td>wore cap barack obama signature look jason jou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question romney obama child contest mitt punch...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[question, e, romney, e, e, obama, e, child, p...</td>\n",
       "      <td>question romney obama child punching contest m...</td>\n",
       "      <td>question romney obama child contest mitt punch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obama debate cracker as cracker tonight</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>[e, obama, e, debates, cracker, ass, cracker, ...</td>\n",
       "      <td>obama debates cracker ass cracker tonight tuned</td>\n",
       "      <td>obama debates cracker ass cracker tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slate blame obama four death libya blame bush ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[rt, slate, blame, e, obama, e, four, deaths, ...</td>\n",
       "      <td>slate blame obama four deaths libya blame bush...</td>\n",
       "      <td>slate blame obama four deaths libya blame bush...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miss point afraid understand big picture dont ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[youre, missing, point, im, afraid, understand...</td>\n",
       "      <td>youre missing point afraid understand bigger p...</td>\n",
       "      <td>missing point afraid understand bigger picture...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class sentiment  \\\n",
       "1  wore cap barack obama signature look jason jou...      0   neutral   \n",
       "2  question romney obama child contest mitt punch...      0   neutral   \n",
       "3            obama debate cracker as cracker tonight      1  positive   \n",
       "4  slate blame obama four death libya blame bush ...      0   neutral   \n",
       "5  miss point afraid understand big picture dont ...      0   neutral   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "1  [kirkpatrick, wore, baseball, cap, embroidered...   \n",
       "2  [question, e, romney, e, e, obama, e, child, p...   \n",
       "3  [e, obama, e, debates, cracker, ass, cracker, ...   \n",
       "4  [rt, slate, blame, e, obama, e, four, deaths, ...   \n",
       "5  [youre, missing, point, im, afraid, understand...   \n",
       "\n",
       "                                        tweet_string  \\\n",
       "1  kirkpatrick wore baseball cap embroidered bara...   \n",
       "2  question romney obama child punching contest m...   \n",
       "3    obama debates cracker ass cracker tonight tuned   \n",
       "4  slate blame obama four deaths libya blame bush...   \n",
       "5  youre missing point afraid understand bigger p...   \n",
       "\n",
       "                                  tweet_string_fdist  \n",
       "1  wore cap barack obama signature look jason jou...  \n",
       "2  question romney obama child contest mitt punch...  \n",
       "3          obama debates cracker ass cracker tonight  \n",
       "4  slate blame obama four deaths libya blame bush...  \n",
       "5  missing point afraid understand bigger picture...  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "obama['tweet'] = obama['tweet_string_fdist'].apply(lambda x: lemmatiser(x))\n",
    "obama.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7167, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wore cap barack obama signature look jason jou...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question romney obama child contest mitt punch...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obama debate cracker as cracker tonight</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slate blame obama four death libya blame bush ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miss point afraid understand big picture dont ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class sentiment\n",
       "1  wore cap barack obama signature look jason jou...      0   neutral\n",
       "2  question romney obama child contest mitt punch...      0   neutral\n",
       "3            obama debate cracker as cracker tonight      1  positive\n",
       "4  slate blame obama four death libya blame bush ...      0   neutral\n",
       "5  miss point afraid understand big picture dont ...      0   neutral"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama = obama.drop(['tweet_token', 'tweet_string', 'tweet_string_fdist'], axis=1)\n",
    "#obama = obama[obama['tweet'].apply(lambda x: len(x.split())>1)]\n",
    "obama.dropna(inplace=True)\n",
    "print(obama.shape)\n",
    "obama.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     3520\n",
      "negative    1968\n",
      "positive    1679\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(obama['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1543, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question romney obama child mitt punch five ob...</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slate blame obama four death libya blame bush ...</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mitt romney make money barack obama make money...</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tonight debate game feel pres obama call romne...</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>guy rather obama critique romney tax plan</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  class sentiment\n",
       "2   question romney obama child mitt punch five ob...      2     mixed\n",
       "4   slate blame obama four death libya blame bush ...      2     mixed\n",
       "6   mitt romney make money barack obama make money...      2     mixed\n",
       "9   tonight debate game feel pres obama call romne...      2     mixed\n",
       "12          guy rather obama critique romney tax plan      2     mixed"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_mixed['class']=obama_mixed['class'].astype(int)\n",
    "obama_mixed['sentiment'] = obama_mixed['class'].apply(lambda x: 'mixed' if x == 2 else 'mixed')\n",
    "obama_mixed['tweet_token'] = obama_mixed['tweet'].apply(lambda stext: tokenize(str(stext)))\n",
    "\n",
    "#remove words with length less than 2\n",
    "obama_mixed['tweet_string'] = obama_mixed['tweet_token'].apply(lambda x:' '.join([item for item in x if len(item)>2]))\n",
    "\n",
    "all_words = ' '.join([text for text in obama_mixed['tweet_string']])\n",
    "tokenized_obama_mixed = nltk.tokenize.word_tokenize(all_words)\n",
    "fdist = FreqDist(tokenized_obama_mixed)\n",
    "obama_mixed['tweet_string_fdist'] = obama_mixed['tweet_token'].apply(lambda x: ' '.join([item for item in x if fdist[item] > 1 ]))\n",
    "#fdist\n",
    "#lemmatize\n",
    "# nltk.download('wordnet') \n",
    "# wordnet_lem = WordNetLemmatizer()\n",
    "# obama_mixed['tweet'] = obama_mixed['tweet_string_fdist'].apply(wordnet_lem.lemmatize)\n",
    "\n",
    "obama_mixed['tweet'] = obama_mixed['tweet_string_fdist'].apply(lambda x: lemmatiser(x))\n",
    "obama_mixed.head(5)\n",
    "obama_mixed = obama_mixed.drop(['tweet_token', 'tweet_string', 'tweet_string_fdist'], axis=1)\n",
    "#obama_mixed = obama_mixed[obama_mixed['tweet'].apply(lambda x: len(x.split())>1)]\n",
    "obama_mixed.dropna(inplace=True)\n",
    "print(obama_mixed.shape)\n",
    "obama_mixed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obama = pd.read_csv('C:/Users/utsav/OneDrive/UIC/Fall_2023/CS_583/Project/Cleaned/obama_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = obama['tweet']\n",
    "df_Y = obama['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X,df_Y,test_size=0.2,random_state = 1551)\n",
    "#X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, ngram_range=(1,2))\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mixed = tfidf_vectorizer.transform(obama_mixed['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "obama_vader = obama.copy(deep=True)\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "obama_vader['polarity'] = obama_vader['tweet'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "obama_vader['predicted'] = obama_vader['polarity'].apply(lambda x: 'positive' if x > 0 else 'neutral' if x==0 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.47      0.45      1968\n",
      "     neutral       0.57      0.34      0.43      3520\n",
      "    positive       0.30      0.52      0.38      1679\n",
      "\n",
      "    accuracy                           0.42      7167\n",
      "   macro avg       0.43      0.45      0.42      7167\n",
      "weighted avg       0.47      0.42      0.42      7167\n",
      "\n",
      "   Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Vader  0.420678   0.467917  0.420678  0.424098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\AppData\\Local\\Temp\\ipykernel_15032\\1424663628.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance = performance.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(obama_vader['sentiment'],obama_vader['predicted']))\n",
    "#performance = pd.DataFrame(columns=['Model','Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "new_data = {'Model': 'Vader',\n",
    "            'Accuracy': accuracy_score(obama_vader['sentiment'],obama_vader['predicted']),\n",
    "            'Precision': precision_score(obama_vader['sentiment'],obama_vader['predicted'], average='weighted'),\n",
    "            'Recall': recall_score(obama_vader['sentiment'],obama_vader['predicted'], average='weighted'),\n",
    "            'F1 Score': f1_score(obama_vader['sentiment'],obama_vader['predicted'], average='weighted')}\n",
    "performance = performance.append(new_data, ignore_index=True)\n",
    "print(performance.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-40 {color: black;background-color: white;}#sk-container-id-40 pre{padding: 0;}#sk-container-id-40 div.sk-toggleable {background-color: white;}#sk-container-id-40 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-40 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-40 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-40 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-40 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-40 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-40 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-40 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-40 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-40 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-40 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-40 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-40 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-40 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-40 div.sk-item {position: relative;z-index: 1;}#sk-container-id-40 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-40 div.sk-item::before, #sk-container-id-40 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-40 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-40 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-40 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-40 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-40 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-40 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-40 div.sk-label-container {text-align: center;}#sk-container-id-40 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-40 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-40\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=5, random_state=44, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" checked><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=5, random_state=44, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=5, random_state=44, solver='saga')"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(solver='saga',C=5,penalty='l2',random_state=44) #4=57%\n",
    "lr_model.fit(X_train_vectors_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.58      0.59       385\n",
      "     neutral       0.66      0.76      0.71       695\n",
      "    positive       0.63      0.47      0.54       354\n",
      "\n",
      "    accuracy                           0.64      1434\n",
      "   macro avg       0.63      0.60      0.61      1434\n",
      "weighted avg       0.64      0.64      0.63      1434\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0                Vader  0.420678   0.467917  0.420678  0.424098\n",
      "1  Logistic Regression  0.638773   0.636332  0.638773  0.633323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\AppData\\Local\\Temp\\ipykernel_15032\\3830438866.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance = performance.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "lr_y_pred = lr_model.predict(X_test_vectors_tfidf)\n",
    "print(classification_report(y_test,lr_y_pred))\n",
    "new_data = {'Model': 'Logistic Regression',\n",
    "            'Accuracy': accuracy_score(y_test,lr_y_pred),\n",
    "            'Precision': precision_score(y_test,lr_y_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test,lr_y_pred, average='weighted'),\n",
    "            'F1 Score': f1_score(y_test,lr_y_pred, average='weighted')}\n",
    "performance = performance.append(new_data, ignore_index=True)\n",
    "print(performance.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-41 {color: black;background-color: white;}#sk-container-id-41 pre{padding: 0;}#sk-container-id-41 div.sk-toggleable {background-color: white;}#sk-container-id-41 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-41 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-41 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-41 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-41 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-41 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-41 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-41 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-41 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-41 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-41 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-41 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-41 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-41 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-41 div.sk-item {position: relative;z-index: 1;}#sk-container-id-41 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-41 div.sk-item::before, #sk-container-id-41 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-41 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-41 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-41 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-41 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-41 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-41 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-41 div.sk-label-container {text-align: center;}#sk-container-id-41 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-41 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-41\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" checked><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectors_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.16      0.26       385\n",
      "     neutral       0.52      0.96      0.67       695\n",
      "    positive       0.84      0.12      0.21       354\n",
      "\n",
      "    accuracy                           0.54      1434\n",
      "   macro avg       0.69      0.41      0.38      1434\n",
      "weighted avg       0.65      0.54      0.45      1434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\AppData\\Local\\Temp\\ipykernel_15032\\922495945.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance = performance.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "nb_y_pred = nb_model.predict(X_test_vectors_tfidf)\n",
    "print(classification_report(y_test,nb_y_pred))\n",
    "new_data = {'Model': 'Naive Bayes',\n",
    "            'Accuracy': accuracy_score(y_test,nb_y_pred),\n",
    "            'Precision': precision_score(y_test,nb_y_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test,nb_y_pred, average='weighted'),\n",
    "            'F1 Score': f1_score(y_test,nb_y_pred, average='weighted')}\n",
    "performance = performance.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1000,9999):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vader</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.467917</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.424098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.638773</td>\n",
       "      <td>0.636332</td>\n",
       "      <td>0.638773</td>\n",
       "      <td>0.633323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.539052</td>\n",
       "      <td>0.645972</td>\n",
       "      <td>0.539052</td>\n",
       "      <td>0.446748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0                Vader  0.420678   0.467917  0.420678  0.424098\n",
       "1  Logistic Regression  0.638773   0.636332  0.638773  0.633323\n",
       "2          Naive Bayes  0.539052   0.645972  0.539052  0.446748"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-42 {color: black;background-color: white;}#sk-container-id-42 pre{padding: 0;}#sk-container-id-42 div.sk-toggleable {background-color: white;}#sk-container-id-42 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-42 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-42 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-42 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-42 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-42 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-42 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-42 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-42 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-42 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-42 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-42 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-42 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-42 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-42 div.sk-item {position: relative;z-index: 1;}#sk-container-id-42 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-42 div.sk-item::before, #sk-container-id-42 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-42 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-42 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-42 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-42 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-42 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-42 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-42 div.sk-label-container {text-align: center;}#sk-container-id-42 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-42 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-42\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" checked><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=4)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection, svm\n",
    "\n",
    "svm_model = svm.SVC(kernel='linear', random_state=4)\n",
    "svm_model.fit(X_train_vectors_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.60      0.60       385\n",
      "     neutral       0.67      0.76      0.71       695\n",
      "    positive       0.63      0.47      0.54       354\n",
      "\n",
      "    accuracy                           0.64      1434\n",
      "   macro avg       0.64      0.61      0.62      1434\n",
      "weighted avg       0.64      0.64      0.64      1434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\AppData\\Local\\Temp\\ipykernel_15032\\141631428.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance = performance.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "svm_y_pred = svm_model.predict(X_test_vectors_tfidf)\n",
    "print(classification_report(y_test,svm_y_pred))\n",
    "new_data = {'Model': 'SVM',\n",
    "            'Accuracy': accuracy_score(y_test,svm_y_pred),\n",
    "            'Precision': precision_score(y_test,svm_y_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test,svm_y_pred, average='weighted'),\n",
    "            'F1 Score': f1_score(y_test,svm_y_pred, average='weighted')}\n",
    "performance = performance.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15147)\t0.0696471516955555\n",
      "  (0, 16077)\t0.6059808658688938\n",
      "  (0, 19344)\t0.5122339799252629\n",
      "  (0, 23872)\t0.35322438266634676\n",
      "  (0, 23901)\t0.4906988381496186\n",
      "  (1, 2160)\t0.30183119241617407\n",
      "  (1, 5275)\t0.12570973870394758\n",
      "  (1, 5500)\t0.3727417167244743\n",
      "  (1, 12414)\t0.2629677625697816\n",
      "  (1, 12438)\t0.16558683028868248\n",
      "  (1, 13480)\t0.25137442887384664\n",
      "  (1, 15147)\t0.04284029471912051\n",
      "  (1, 15424)\t0.21440017978811832\n",
      "  (1, 19121)\t0.20243378622854646\n",
      "  (1, 19152)\t0.28893002028231923\n",
      "  (1, 19583)\t0.23884969275686901\n",
      "  (1, 21976)\t0.3727417167244743\n",
      "  (1, 23029)\t0.3057957047406717\n",
      "  (1, 23922)\t0.18118553672102053\n",
      "  (1, 23980)\t0.2231082901435064\n",
      "  (1, 25813)\t0.22368203573607245\n",
      "  (2, 849)\t0.226846685206795\n",
      "  (2, 3036)\t0.20706274445730258\n",
      "  (2, 3057)\t0.3599853456977993\n",
      "  (2, 3989)\t0.2138549390025235\n",
      "  :\t:\n",
      "  (1432, 14546)\t0.1996691115045924\n",
      "  (1432, 15147)\t0.045512536497552575\n",
      "  (1432, 15214)\t0.3653616317561438\n",
      "  (1432, 19714)\t0.30142153513868825\n",
      "  (1432, 20798)\t0.16506372085838966\n",
      "  (1432, 20858)\t0.3959921634015153\n",
      "  (1432, 25329)\t0.1611988490177723\n",
      "  (1432, 25387)\t0.19738943905326373\n",
      "  (1433, 1102)\t0.3110653622382492\n",
      "  (1433, 2538)\t0.2551966882107027\n",
      "  (1433, 2559)\t0.3110653622382492\n",
      "  (1433, 2560)\t0.3110653622382492\n",
      "  (1433, 3312)\t0.2675780022227289\n",
      "  (1433, 7446)\t0.19730531631530493\n",
      "  (1433, 9067)\t0.15428896975306863\n",
      "  (1433, 14176)\t0.2870040340039411\n",
      "  (1433, 14956)\t0.1838915645998643\n",
      "  (1433, 15147)\t0.03575165106900839\n",
      "  (1433, 15639)\t0.19730531631530493\n",
      "  (1433, 17601)\t0.21706038524178117\n",
      "  (1433, 18128)\t0.2675780022227289\n",
      "  (1433, 18131)\t0.2870040340039411\n",
      "  (1433, 24352)\t0.20885458402173485\n",
      "  (1433, 24362)\t0.27292905926932765\n",
      "  (1433, 26534)\t0.18619129004856386\n"
     ]
    }
   ],
   "source": [
    "print(X_test_vectors_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1543, 27031)\n",
      "(1434, 27031)\n",
      "(5733, 27031)\n"
     ]
    }
   ],
   "source": [
    "print(X_mixed.shape)\n",
    "print(X_test_vectors_tfidf.shape)\n",
    "print(X_train_vectors_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vader</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.467917</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.424098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.638773</td>\n",
       "      <td>0.636332</td>\n",
       "      <td>0.638773</td>\n",
       "      <td>0.633323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.539052</td>\n",
       "      <td>0.645972</td>\n",
       "      <td>0.539052</td>\n",
       "      <td>0.446748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.644351</td>\n",
       "      <td>0.642072</td>\n",
       "      <td>0.644351</td>\n",
       "      <td>0.638760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0                Vader  0.420678   0.467917  0.420678  0.424098\n",
       "1  Logistic Regression  0.638773   0.636332  0.638773  0.633323\n",
       "2          Naive Bayes  0.539052   0.645972  0.539052  0.446748\n",
       "3                  SVM  0.644351   0.642072  0.644351  0.638760"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "mixed_pred = svm_model.predict(X_mixed)\n",
    "print(mixed_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #your code here\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# clf = KNeighborsClassifier(n_neighbors = 15)\n",
    "# clf.fit(X_train_vectors_tfidf, y_train)\n",
    "# y_pred_sklearn = clf.predict(X_test_vectors_tfidf)\n",
    "# print(classification_report(y_test,y_pred_sklearn))\n",
    "# new_data = {'Model': 'KNN',\n",
    "#             'Accuracy': accuracy_score(y_test,y_pred_sklearn),\n",
    "#             'Precision': precision_score(y_test,y_pred_sklearn, average='weighted'),\n",
    "#             'Recall': recall_score(y_test,y_pred_sklearn, average='weighted'),\n",
    "#             'F1 Score': f1_score(y_test,y_pred_sklearn, average='weighted')}\n",
    "# performance = performance.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.30      0.41       385\n",
      "     neutral       0.59      0.72      0.65       695\n",
      "    positive       0.47      0.53      0.49       354\n",
      "\n",
      "    accuracy                           0.56      1434\n",
      "   macro avg       0.56      0.52      0.52      1434\n",
      "weighted avg       0.57      0.56      0.55      1434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utsav\\AppData\\Local\\Temp\\ipykernel_15032\\3281839059.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance = performance.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV#create new a knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn2 = KNeighborsClassifier()#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)#fit model to data\n",
    "clf = knn_gscv.fit(X_train_vectors_tfidf, y_train)\n",
    "y_pred_sklearn = clf.predict(X_test_vectors_tfidf)\n",
    "print(classification_report(y_test,y_pred_sklearn))\n",
    "new_data = {'Model': 'KNN',\n",
    "            'Accuracy': accuracy_score(y_test,y_pred_sklearn),\n",
    "            'Precision': precision_score(y_test,y_pred_sklearn, average='weighted'),\n",
    "            'Recall': recall_score(y_test,y_pred_sklearn, average='weighted'),\n",
    "            'F1 Score': f1_score(y_test,y_pred_sklearn, average='weighted')}\n",
    "performance = performance.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vader</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.467917</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.424098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.638773</td>\n",
       "      <td>0.636332</td>\n",
       "      <td>0.638773</td>\n",
       "      <td>0.633323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.539052</td>\n",
       "      <td>0.645972</td>\n",
       "      <td>0.539052</td>\n",
       "      <td>0.446748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.644351</td>\n",
       "      <td>0.642072</td>\n",
       "      <td>0.644351</td>\n",
       "      <td>0.638760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.546546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0                Vader  0.420678   0.467917  0.420678  0.424098\n",
       "1  Logistic Regression  0.638773   0.636332  0.638773  0.633323\n",
       "2          Naive Bayes  0.539052   0.645972  0.539052  0.446748\n",
       "3                  SVM  0.644351   0.642072  0.644351  0.638760\n",
       "4                  KNN  0.560669   0.566667  0.560669  0.546546"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_xgb = obama.copy(deep=True)\n",
    "obama_xgb.drop(['sentiment'], axis=1)\n",
    "obama_xgb['class'] = obama_xgb['class'].map({1: 1, 0: 0 ,-1: 2})\n",
    "df_X_xgb = obama_xgb['tweet']\n",
    "df_Y_xgb = obama_xgb['class']\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(df_X_xgb,df_Y_xgb,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_features=10000)\n",
    "X_train_vectors_tfidf_xgb = tfidf_vectorizer.fit_transform(X_train_xgb)\n",
    "X_test_vectors_tfidf_xgb = tfidf_vectorizer.transform(X_test_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wore cap barack obama signature look jason jou...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question romney obama child contest mitt punch...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obama debate cracker as cracker tonight</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slate blame obama four death libya blame bush ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miss point afraid understand big picture dont ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class sentiment\n",
       "1  wore cap barack obama signature look jason jou...      0   neutral\n",
       "2  question romney obama child contest mitt punch...      0   neutral\n",
       "3            obama debate cracker as cracker tonight      1  positive\n",
       "4  slate blame obama four death libya blame bush ...      0   neutral\n",
       "5  miss point afraid understand big picture dont ...      0   neutral"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6387726638772664"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=1000, max_depth=15, eta=0.1, subsample=0.7, colsample_bytree=1)\n",
    "\n",
    "xgb.fit(X_train_vectors_tfidf_xgb,y_train_xgb)\n",
    "xgb.score(X_test_vectors_tfidf_xgb,y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 ... 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test_vectors_tfidf_xgb)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from: https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\utsav\\anaconda3\\envs\\cs418\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building Word2Vec model\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "obama['clean_text_tok']=[nltk.word_tokenize(i) for i in obama['tweet']] \n",
    "model = Word2Vec(obama['clean_text_tok'],min_count=1) \n",
    "w2v = dict(zip(model.wv.index_to_key , model.wv.vectors))   \n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_val_vectors_w2v = modelw.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-43 {color: black;background-color: white;}#sk-container-id-43 pre{padding: 0;}#sk-container-id-43 div.sk-toggleable {background-color: white;}#sk-container-id-43 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-43 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-43 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-43 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-43 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-43 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-43 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-43 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-43 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-43 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-43 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-43 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-43 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-43 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-43 div.sk-item {position: relative;z-index: 1;}#sk-container-id-43 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-43 div.sk-item::before, #sk-container-id-43 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-43 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-43 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-43 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-43 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-43 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-43 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-43 div.sk-label-container {text-align: center;}#sk-container-id-43 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-43 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-43\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, random_state=4, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" checked><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, random_state=4, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, random_state=4, solver='liblinear')"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model2 = LogisticRegression(solver='liblinear',C=10,penalty='l2',random_state=4) #4=57%\n",
    "lr_model2.fit(X_train_vectors_w2v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.09      0.16       385\n",
      "     neutral       0.51      0.96      0.66       695\n",
      "    positive       0.63      0.11      0.19       354\n",
      "\n",
      "    accuracy                           0.52      1434\n",
      "   macro avg       0.61      0.39      0.34      1434\n",
      "weighted avg       0.58      0.52      0.41      1434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_y_pred2 = lr_model2.predict(X_val_vectors_w2v)\n",
    "print(classification_report(y_test,lr_y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS418",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
